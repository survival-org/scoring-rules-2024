[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Supplementary Material",
    "section": "",
    "text": "This section demonstrates how a deliberately simple, uninformative survival model—the degenerate model—can outperform established methods under the Integrated Survival Brier Score (ISBS). The model entirely ignores covariates and instead outputs a flat survival function that drops from 1 to 0 at a fixed quantile of observed times.\nWhile this model is intentionally unrealistic, its performance exposes a key weakness in ISBS: it can be minimized by predictions that offer no individualization or clinical utility. This reinforces our theoretical findings that ISBS is not a proper scoring rule.\nBelow, we define the degenerate model in mlr3proba, tune it over the quantile cutoff with ISBS, and compare its ISBS score and other evaluation measures to Cox, Kaplan-Meier, and Random Survival Forest (RSF) learners on the survival::rats dataset.\nLoad libraries:\n\n\nCode\nlibrary(R6)\nlibrary(mlr3proba)\nlibrary(mlr3extralearners)\nlibrary(mlr3tuning)\n\n\nDefine the degenerate model:\n\n\nCode\nLearnerSurvDegenerate = R6Class(\"LearnerSurvDegenerate\",\n  inherit = LearnerSurv,\n  public = list(\n    initialize = function() {\n      super$initialize(\n        id = \"surv.degenerate\",\n        predict_types = c(\"distr\"),\n        feature_types = c(\"logical\", \"integer\", \"numeric\", \"character\", \"factor\", \"ordered\"),\n        properties = \"missings\",\n        packages = c(\"survival\", \"distr6\"),\n        label = \"Degenerate Estimator\",\n        param_set = ps(\n           quantile = p_dbl(0, 1)\n        )\n      )\n    }\n  ),\n\n  private = list(\n    .train = function(task) {\n      list(time = task$truth()[,1L]) # store observed times\n    },\n\n    .predict = function(task) {\n      quantile_ps = self$param_set$values$quantile\n      times = sort(unique(self$model$time))\n      surv = matrix(nrow = task$nrow, ncol = length(times))\n\n      q_t = quantile(seq.int(length(times)), quantile_ps)[[1]]\n      \n      # same S for all test observations, sharp drop from 1 to 0 at q_t\n      surv[, 1:floor(q_t)] = 1\n      surv[, ceiling(q_t):ncol(surv)] = 0\n      colnames(surv) = times\n      .surv_return(times = times, surv = surv)\n    }\n  )\n)\n\n\nWe tune the degenerate model to find the optimal quantile to switch the prediction at:\n\n\nCode\nl = LearnerSurvDegenerate$new()\nl$param_set$values$quantile = to_tune(0, 1)\n\n# ISBS\nm = msr(\"surv.graf\")\n\n# Tune the quantile parameter of the degenerate model\nat = auto_tuner(\n  tuner = tnr(\"grid_search\", resolution = 20),\n  learner = l,\n  resampling = rsmp(\"holdout\"),\n  measure = m,\n)\n\n\nIn our benchmark experiment we compare to the Cox PH, Random Forest, and Kaplan-Meier using 3-fold outer cross-validation.\n\n\nCode\n# Seed for reproducibility\nset.seed(20250418)\n\n# Compare to Cox PH and Kaplan-Meier\nlearners = c(lrns(c(\"surv.coxph\", \"surv.kaplan\", \"surv.rfsrc\")), at)\n\nr = rsmp(\"cv\", folds = 3)\nbm = benchmark(benchmark_grid(tasks = tsk(\"rats\"), learners = learners, resamplings = r))\n\n\nTo evaluate the benchmark we use Harrell’s C, D-calibration, RCLL, the SBS evaluated at three quantiles, and the ISBS:\n\n\nCode\nq25 = quantile(tsk(\"rats\")$times(), 0.25)\nq50 = quantile(tsk(\"rats\")$times(), 0.50)\nq75 = quantile(tsk(\"rats\")$times(), 0.75)\n\nmeasures = c(msrs(\n  c(\"surv.cindex\", \"surv.dcalib\", \"surv.rcll\")),\n  msr(\"surv.graf\", integrated = FALSE, times = q25, id = \"SBS_q25\"),\n  msr(\"surv.graf\", integrated = FALSE, times = q50, id = \"SBS_q0.5\"),\n  msr(\"surv.graf\", integrated = FALSE, times = q75, id = \"SBS_q0.75\"),\n  msr(\"surv.graf\", id = \"ISBS\")\n)\n\n\nFinally score results:\n\n\nCode\nbm$aggregate(measures)[, c(4, 7:13)]\n\n\n              learner_id surv.cindex  surv.dcalib surv.rcll    SBS_q25\n                  &lt;char&gt;       &lt;num&gt;        &lt;num&gt;     &lt;num&gt;      &lt;num&gt;\n1:            surv.coxph   0.7637313 4.629203e-01  3.626923 0.07522030\n2:           surv.kaplan   0.5000000 9.691005e-01  3.676610 0.07700273\n3:            surv.rfsrc   0.7516121 8.259461e-01  3.634021 0.07576037\n4: surv.degenerate.tuned   0.5000000 1.283224e+10 17.039130 0.08399497\n    SBS_q0.5 SBS_q0.75       ISBS\n       &lt;num&gt;     &lt;num&gt;      &lt;num&gt;\n1: 0.1091271  2.068774 0.06850171\n2: 0.1212525  2.327660 0.07341427\n3: 0.1084741  1.649696 0.06500299\n4: 0.1400008  0.000000 0.06306716\n\n\nAnd we see the degenerate model performs the best with respect to ISBS and SBS at the 75% quantile of observed times, but worse with respect to all other measures."
  },
  {
    "objectID": "index.html#degenerate-model-exploits-isbs-scoring-rule",
    "href": "index.html#degenerate-model-exploits-isbs-scoring-rule",
    "title": "Supplementary Material",
    "section": "",
    "text": "This section demonstrates how a deliberately simple, uninformative survival model—the degenerate model—can outperform established methods under the Integrated Survival Brier Score (ISBS). The model entirely ignores covariates and instead outputs a flat survival function that drops from 1 to 0 at a fixed quantile of observed times.\nWhile this model is intentionally unrealistic, its performance exposes a key weakness in ISBS: it can be minimized by predictions that offer no individualization or clinical utility. This reinforces our theoretical findings that ISBS is not a proper scoring rule.\nBelow, we define the degenerate model in mlr3proba, tune it over the quantile cutoff with ISBS, and compare its ISBS score and other evaluation measures to Cox, Kaplan-Meier, and Random Survival Forest (RSF) learners on the survival::rats dataset.\nLoad libraries:\n\n\nCode\nlibrary(R6)\nlibrary(mlr3proba)\nlibrary(mlr3extralearners)\nlibrary(mlr3tuning)\n\n\nDefine the degenerate model:\n\n\nCode\nLearnerSurvDegenerate = R6Class(\"LearnerSurvDegenerate\",\n  inherit = LearnerSurv,\n  public = list(\n    initialize = function() {\n      super$initialize(\n        id = \"surv.degenerate\",\n        predict_types = c(\"distr\"),\n        feature_types = c(\"logical\", \"integer\", \"numeric\", \"character\", \"factor\", \"ordered\"),\n        properties = \"missings\",\n        packages = c(\"survival\", \"distr6\"),\n        label = \"Degenerate Estimator\",\n        param_set = ps(\n           quantile = p_dbl(0, 1)\n        )\n      )\n    }\n  ),\n\n  private = list(\n    .train = function(task) {\n      list(time = task$truth()[,1L]) # store observed times\n    },\n\n    .predict = function(task) {\n      quantile_ps = self$param_set$values$quantile\n      times = sort(unique(self$model$time))\n      surv = matrix(nrow = task$nrow, ncol = length(times))\n\n      q_t = quantile(seq.int(length(times)), quantile_ps)[[1]]\n      \n      # same S for all test observations, sharp drop from 1 to 0 at q_t\n      surv[, 1:floor(q_t)] = 1\n      surv[, ceiling(q_t):ncol(surv)] = 0\n      colnames(surv) = times\n      .surv_return(times = times, surv = surv)\n    }\n  )\n)\n\n\nWe tune the degenerate model to find the optimal quantile to switch the prediction at:\n\n\nCode\nl = LearnerSurvDegenerate$new()\nl$param_set$values$quantile = to_tune(0, 1)\n\n# ISBS\nm = msr(\"surv.graf\")\n\n# Tune the quantile parameter of the degenerate model\nat = auto_tuner(\n  tuner = tnr(\"grid_search\", resolution = 20),\n  learner = l,\n  resampling = rsmp(\"holdout\"),\n  measure = m,\n)\n\n\nIn our benchmark experiment we compare to the Cox PH, Random Forest, and Kaplan-Meier using 3-fold outer cross-validation.\n\n\nCode\n# Seed for reproducibility\nset.seed(20250418)\n\n# Compare to Cox PH and Kaplan-Meier\nlearners = c(lrns(c(\"surv.coxph\", \"surv.kaplan\", \"surv.rfsrc\")), at)\n\nr = rsmp(\"cv\", folds = 3)\nbm = benchmark(benchmark_grid(tasks = tsk(\"rats\"), learners = learners, resamplings = r))\n\n\nTo evaluate the benchmark we use Harrell’s C, D-calibration, RCLL, the SBS evaluated at three quantiles, and the ISBS:\n\n\nCode\nq25 = quantile(tsk(\"rats\")$times(), 0.25)\nq50 = quantile(tsk(\"rats\")$times(), 0.50)\nq75 = quantile(tsk(\"rats\")$times(), 0.75)\n\nmeasures = c(msrs(\n  c(\"surv.cindex\", \"surv.dcalib\", \"surv.rcll\")),\n  msr(\"surv.graf\", integrated = FALSE, times = q25, id = \"SBS_q25\"),\n  msr(\"surv.graf\", integrated = FALSE, times = q50, id = \"SBS_q0.5\"),\n  msr(\"surv.graf\", integrated = FALSE, times = q75, id = \"SBS_q0.75\"),\n  msr(\"surv.graf\", id = \"ISBS\")\n)\n\n\nFinally score results:\n\n\nCode\nbm$aggregate(measures)[, c(4, 7:13)]\n\n\n              learner_id surv.cindex  surv.dcalib surv.rcll    SBS_q25\n                  &lt;char&gt;       &lt;num&gt;        &lt;num&gt;     &lt;num&gt;      &lt;num&gt;\n1:            surv.coxph   0.7637313 4.629203e-01  3.626923 0.07522030\n2:           surv.kaplan   0.5000000 9.691005e-01  3.676610 0.07700273\n3:            surv.rfsrc   0.7516121 8.259461e-01  3.634021 0.07576037\n4: surv.degenerate.tuned   0.5000000 1.283224e+10 17.039130 0.08399497\n    SBS_q0.5 SBS_q0.75       ISBS\n       &lt;num&gt;     &lt;num&gt;      &lt;num&gt;\n1: 0.1091271  2.068774 0.06850171\n2: 0.1212525  2.327660 0.07341427\n3: 0.1084741  1.649696 0.06500299\n4: 0.1400008  0.000000 0.06306716\n\n\nAnd we see the degenerate model performs the best with respect to ISBS and SBS at the 75% quantile of observed times, but worse with respect to all other measures."
  }
]